{"env_info": "sys.platform: linux\nPython: 3.9.11 (main, Mar 29 2022, 19:08:29) [GCC 7.5.0]\nCUDA available: True\nGPU 0: Tesla T4\nCUDA_HOME: /root/miniconda3/envs/manhdq\nNVCC: Cuda compilation tools, release 11.3, V11.3.58\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\nPyTorch: 1.11.0+cu113\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.3\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.2\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.12.0+cu113\nOpenCV: 4.4.0\nMMCV: 1.5.3\nMMCV Compiler: n/a\nMMCV CUDA Compiler: n/a\nMMDetection: 2.7.0+", "config": "optimizer = dict(type='Adam', lr=0.000625, weight_decay=0.0005)\noptimizer_config = dict(grad_clip=None)\nlr_mult = 8\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=10,\n    warmup_ratio=0.001,\n    step=[32, 48])\ntotal_epochs = 64\ncheckpoint_config = dict(interval=5)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = '/home/manhdq/ID_Card_Information_Extraction/ckpts/keypoint_detector_weights/cmt_final_500m_kpts_weights/best.pth'\nresume_from = None\nworkflow = [('train', 1)]\ndataset_type = 'RetinaFaceDataset'\ndata_root = '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd'\ntrain_root = '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/dummy_v1'\nval_root = '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean'\nimg_norm_cfg = dict(\n    mean=[127.5, 127.5, 127.5], std=[128.0, 128.0, 128.0], to_rgb=True)\nalbu_train_transforms = [\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(\n                type='Affine',\n                scale=None,\n                rotate=(-90, 90),\n                shear=None,\n                interpolation=0,\n                fit_output=True)\n        ],\n        p=0.6),\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(type='MotionBlur'),\n            dict(type='GaussianBlur', blur_limit=3)\n        ],\n        p=0.2),\n    dict(type='ToGray', p=0.2)\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile', to_float32=True),\n    dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n    dict(\n        type='RandomSquareCrop',\n        crop_choice=[0.3, 0.45, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]),\n    dict(type='Resize', img_scale=(640, 640), keep_ratio=False),\n    dict(\n        type='RandomFlip',\n        flip_ratio=0.5,\n        direction=['horizontal', 'vertical', 'diagonal']),\n    dict(\n        type='PhotoMetricDistortion',\n        brightness_delta=32,\n        contrast_range=(0.5, 1.5),\n        saturation_range=(0.5, 1.5),\n        hue_delta=18),\n    dict(\n        type='Normalize',\n        mean=[127.5, 127.5, 127.5],\n        std=[128.0, 128.0, 128.0],\n        to_rgb=True),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=[\n            'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n            'gt_keypointss'\n        ])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(640, 640),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.0),\n            dict(\n                type='Normalize',\n                mean=[127.5, 127.5, 127.5],\n                std=[128.0, 128.0, 128.0],\n                to_rgb=True),\n            dict(type='Pad', size=(640, 640), pad_val=0),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=32,\n    workers_per_gpu=8,\n    train=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/dummy_v1/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/dummy_v1/images',\n        pipeline=[\n            dict(type='LoadImageFromFile', to_float32=True),\n            dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n            dict(\n                type='RandomSquareCrop',\n                crop_choice=[\n                    0.3, 0.45, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0\n                ]),\n            dict(type='Resize', img_scale=(640, 640), keep_ratio=False),\n            dict(\n                type='RandomFlip',\n                flip_ratio=0.5,\n                direction=['horizontal', 'vertical', 'diagonal']),\n            dict(\n                type='PhotoMetricDistortion',\n                brightness_delta=32,\n                contrast_range=(0.5, 1.5),\n                saturation_range=(0.5, 1.5),\n                hue_delta=18),\n            dict(\n                type='Normalize',\n                mean=[127.5, 127.5, 127.5],\n                std=[128.0, 128.0, 128.0],\n                to_rgb=True),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_keypointss'\n                ])\n        ]),\n    val=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/images',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 640),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', flip_ratio=0.0),\n                    dict(\n                        type='Normalize',\n                        mean=[127.5, 127.5, 127.5],\n                        std=[128.0, 128.0, 128.0],\n                        to_rgb=True),\n                    dict(type='Pad', size=(640, 640), pad_val=0),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_keypointss'\n                        ])\n                ])\n        ]),\n    infer=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/images',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 640),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', flip_ratio=0.0),\n                    dict(\n                        type='Normalize',\n                        mean=[127.5, 127.5, 127.5],\n                        std=[128.0, 128.0, 128.0],\n                        to_rgb=True),\n                    dict(type='Pad', size=(640, 640), pad_val=0),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_keypointss'\n                        ])\n                ])\n        ]),\n    test=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/images',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 640),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', flip_ratio=0.0),\n                    dict(\n                        type='Normalize',\n                        mean=[127.5, 127.5, 127.5],\n                        std=[128.0, 128.0, 128.0],\n                        to_rgb=True),\n                    dict(type='Pad', size=(640, 640), pad_val=0),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nmodel = dict(\n    type='SCRFD',\n    backbone=dict(\n        type='MobileNetV1',\n        block_cfg=dict(\n            stage_blocks=(2, 3, 2, 6), stage_planes=[16, 16, 40, 72, 152,\n                                                     288])),\n    neck=dict(\n        type='PAFPN',\n        in_channels=[40, 72, 152, 288],\n        out_channels=16,\n        start_level=1,\n        add_extra_convs='on_output',\n        num_outs=3),\n    bbox_head=dict(\n        type='SCRFDHead',\n        num_classes=1,\n        in_channels=16,\n        stacked_convs=2,\n        feat_channels=64,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        cls_reg_share=True,\n        strides_share=False,\n        dw_conv=True,\n        scale_mode=0,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            ratios=[1.0],\n            scales=[1, 2],\n            base_sizes=[16, 64, 256],\n            strides=[8, 16, 32]),\n        loss_cls=dict(\n            type='QualityFocalLoss',\n            use_sigmoid=True,\n            beta=2.0,\n            loss_weight=1.0),\n        loss_dfl=False,\n        reg_max=8,\n        loss_bbox=dict(type='DIoULoss', loss_weight=1.0),\n        use_kps=True,\n        loss_kps=dict(\n            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.5),\n        train_cfg=dict(\n            assigner=dict(type='ATSSAssigner', topk=9),\n            allowed_border=-1,\n            pos_weight=-1,\n            debug=False),\n        test_cfg=dict(\n            nms_pre=-1,\n            min_bbox_size=0,\n            score_thr=0.02,\n            nms=dict(type='nms', iou_threshold=0.45),\n            max_per_img=-1)))\ntrain_cfg = dict(\n    assigner=dict(type='ATSSAssigner', topk=9),\n    allowed_border=-1,\n    pos_weight=-1,\n    debug=False)\nval_cfg = dict(\n    nms_pre=-1,\n    min_bbox_size=0,\n    score_thr=0.02,\n    nms=dict(type='nms', iou_threshold=0.45),\n    max_per_img=-1)\ntest_cfg = dict(\n    nms_pre=-1,\n    min_bbox_size=0,\n    score_thr=0.02,\n    nms=dict(type='nms', iou_threshold=0.45),\n    max_per_img=-1)\nepoch_multi = 1\nevaluation = dict(interval=5, metric='mAP')\nwork_dir = './work_dirs/scrfd_cccd_500m_bnkps_dummy'\ngpu_ids = range(0, 1)\n", "seed": null, "exp_name": "scrfd_cccd_500m_bnkps_dummy.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.00063, "memory": 4011, "data_time": 0.61076, "loss_cls": 0.46311, "loss_bbox": 0.13883, "loss_kps": 36.33374, "loss": 36.93568, "time": 1.06187}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.00063, "memory": 4011, "data_time": 0.06218, "loss_cls": 0.3624, "loss_bbox": 0.13763, "loss_kps": 29.12309, "loss": 29.62312, "time": 0.514}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.00063, "memory": 4011, "data_time": 0.06739, "loss_cls": 0.35223, "loss_bbox": 0.13802, "loss_kps": 26.04386, "loss": 26.53411, "time": 0.57241}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.00063, "memory": 4011, "data_time": 0.06202, "loss_cls": 0.31809, "loss_bbox": 0.12691, "loss_kps": 22.37209, "loss": 22.81709, "time": 0.8051}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.00063, "memory": 4011, "data_time": 0.06566, "loss_cls": 0.30966, "loss_bbox": 0.12895, "loss_kps": 21.1044, "loss": 21.54301, "time": 0.81122}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.00063, "memory": 4011, "data_time": 0.05904, "loss_cls": 0.31204, "loss_bbox": 0.12705, "loss_kps": 18.09859, "loss": 18.53768, "time": 0.81025}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.00063, "memory": 4011, "data_time": 0.05761, "loss_cls": 0.30977, "loss_bbox": 0.1269, "loss_kps": 16.76622, "loss": 17.20288, "time": 0.8062}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.00063, "memory": 4011, "data_time": 0.06045, "loss_cls": 0.28395, "loss_bbox": 0.12649, "loss_kps": 15.38877, "loss": 15.79921, "time": 0.77426}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.00063, "memory": 4011, "data_time": 0.06473, "loss_cls": 0.29697, "loss_bbox": 0.12098, "loss_kps": 14.26832, "loss": 14.68628, "time": 0.81297}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.00063, "memory": 4011, "data_time": 0.58829, "loss_cls": 0.28752, "loss_bbox": 0.11715, "loss_kps": 13.94115, "loss": 14.34583, "time": 1.34245}
{"mode": "train", "epoch": 2, "iter": 100, "lr": 0.00063, "memory": 4011, "data_time": 0.06088, "loss_cls": 0.28731, "loss_bbox": 0.11895, "loss_kps": 13.27507, "loss": 13.68134, "time": 0.81296}
{"mode": "train", "epoch": 2, "iter": 150, "lr": 0.00063, "memory": 4011, "data_time": 0.05833, "loss_cls": 0.28151, "loss_bbox": 0.1134, "loss_kps": 12.40769, "loss": 12.80259, "time": 0.78714}
{"mode": "train", "epoch": 2, "iter": 200, "lr": 0.00063, "memory": 4011, "data_time": 0.06622, "loss_cls": 0.26999, "loss_bbox": 0.11347, "loss_kps": 13.22436, "loss": 13.60782, "time": 0.81061}
{"mode": "train", "epoch": 2, "iter": 250, "lr": 0.00063, "memory": 4011, "data_time": 0.06387, "loss_cls": 0.2764, "loss_bbox": 0.1129, "loss_kps": 11.28861, "loss": 11.67791, "time": 0.81684}
{"mode": "train", "epoch": 2, "iter": 300, "lr": 0.00063, "memory": 4011, "data_time": 0.06145, "loss_cls": 0.26766, "loss_bbox": 0.11102, "loss_kps": 10.90693, "loss": 11.2856, "time": 0.81741}
{"mode": "train", "epoch": 2, "iter": 350, "lr": 0.00063, "memory": 4011, "data_time": 0.05932, "loss_cls": 0.26578, "loss_bbox": 0.10781, "loss_kps": 11.56078, "loss": 11.93438, "time": 0.77215}
{"mode": "train", "epoch": 2, "iter": 400, "lr": 0.00063, "memory": 4011, "data_time": 0.061, "loss_cls": 0.26023, "loss_bbox": 0.10897, "loss_kps": 11.28361, "loss": 11.65282, "time": 0.82782}
{"mode": "train", "epoch": 2, "iter": 450, "lr": 0.00063, "memory": 4011, "data_time": 0.06856, "loss_cls": 0.25576, "loss_bbox": 0.11015, "loss_kps": 11.6323, "loss": 11.99821, "time": 0.66656}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.00063, "memory": 4011, "data_time": 0.6038, "loss_cls": 0.26243, "loss_bbox": 0.10701, "loss_kps": 11.23073, "loss": 11.60017, "time": 1.05838}
{"mode": "train", "epoch": 3, "iter": 100, "lr": 0.00063, "memory": 4011, "data_time": 0.06158, "loss_cls": 0.26287, "loss_bbox": 0.10628, "loss_kps": 10.82813, "loss": 11.19728, "time": 0.51551}
{"mode": "train", "epoch": 3, "iter": 150, "lr": 0.00063, "memory": 4011, "data_time": 0.06173, "loss_cls": 0.25156, "loss_bbox": 0.10429, "loss_kps": 11.35727, "loss": 11.71312, "time": 0.51963}
{"mode": "train", "epoch": 3, "iter": 200, "lr": 0.00063, "memory": 4011, "data_time": 0.06305, "loss_cls": 0.2465, "loss_bbox": 0.10347, "loss_kps": 9.5063, "loss": 9.85627, "time": 0.51643}
{"mode": "train", "epoch": 3, "iter": 250, "lr": 0.00063, "memory": 4011, "data_time": 0.0655, "loss_cls": 0.24929, "loss_bbox": 0.10199, "loss_kps": 10.3344, "loss": 10.68568, "time": 0.51541}
{"mode": "train", "epoch": 3, "iter": 300, "lr": 0.00063, "memory": 4011, "data_time": 0.06611, "loss_cls": 0.24781, "loss_bbox": 0.09985, "loss_kps": 9.28201, "loss": 9.62967, "time": 0.521}
{"mode": "train", "epoch": 3, "iter": 350, "lr": 0.00063, "memory": 4011, "data_time": 0.06154, "loss_cls": 0.25499, "loss_bbox": 0.10344, "loss_kps": 9.94071, "loss": 10.29914, "time": 0.51798}
{"mode": "train", "epoch": 3, "iter": 400, "lr": 0.00063, "memory": 4011, "data_time": 0.06576, "loss_cls": 0.24718, "loss_bbox": 0.09995, "loss_kps": 8.90417, "loss": 9.25129, "time": 0.52391}
{"mode": "train", "epoch": 3, "iter": 450, "lr": 0.00063, "memory": 4011, "data_time": 0.06684, "loss_cls": 0.2482, "loss_bbox": 0.0985, "loss_kps": 10.07715, "loss": 10.42385, "time": 0.52045}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 0.00063, "memory": 4011, "data_time": 0.60908, "loss_cls": 0.24719, "loss_bbox": 0.09868, "loss_kps": 10.00333, "loss": 10.3492, "time": 1.06429}
{"mode": "train", "epoch": 4, "iter": 100, "lr": 0.00063, "memory": 4011, "data_time": 0.06762, "loss_cls": 0.24165, "loss_bbox": 0.1009, "loss_kps": 8.34229, "loss": 8.68484, "time": 0.52438}
{"mode": "train", "epoch": 4, "iter": 150, "lr": 0.00063, "memory": 4011, "data_time": 0.06198, "loss_cls": 0.2517, "loss_bbox": 0.09735, "loss_kps": 9.67697, "loss": 10.02602, "time": 0.61528}
{"mode": "train", "epoch": 4, "iter": 200, "lr": 0.00063, "memory": 4011, "data_time": 0.06342, "loss_cls": 0.23977, "loss_bbox": 0.09559, "loss_kps": 9.60637, "loss": 9.94173, "time": 0.80202}
{"mode": "train", "epoch": 4, "iter": 250, "lr": 0.00063, "memory": 4011, "data_time": 0.06221, "loss_cls": 0.24083, "loss_bbox": 0.09591, "loss_kps": 9.2468, "loss": 9.58354, "time": 0.82637}
{"mode": "train", "epoch": 4, "iter": 300, "lr": 0.00063, "memory": 4011, "data_time": 0.06239, "loss_cls": 0.23158, "loss_bbox": 0.0968, "loss_kps": 9.48948, "loss": 9.81785, "time": 0.81594}
{"mode": "train", "epoch": 4, "iter": 350, "lr": 0.00063, "memory": 4011, "data_time": 0.05733, "loss_cls": 0.23248, "loss_bbox": 0.0983, "loss_kps": 8.94679, "loss": 9.27756, "time": 0.81119}
{"mode": "train", "epoch": 4, "iter": 400, "lr": 0.00063, "memory": 4011, "data_time": 0.06014, "loss_cls": 0.24046, "loss_bbox": 0.09647, "loss_kps": 8.50435, "loss": 8.84128, "time": 0.78133}
{"mode": "train", "epoch": 4, "iter": 450, "lr": 0.00063, "memory": 4011, "data_time": 0.06296, "loss_cls": 0.23144, "loss_bbox": 0.09487, "loss_kps": 8.67483, "loss": 9.00113, "time": 0.83288}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 0.00063, "memory": 4011, "data_time": 0.60084, "loss_cls": 0.23572, "loss_bbox": 0.09287, "loss_kps": 8.71253, "loss": 9.04112, "time": 1.36065}
{"mode": "train", "epoch": 5, "iter": 100, "lr": 0.00063, "memory": 4011, "data_time": 0.06068, "loss_cls": 0.23492, "loss_bbox": 0.09315, "loss_kps": 8.84624, "loss": 9.1743, "time": 0.81306}
{"mode": "train", "epoch": 5, "iter": 150, "lr": 0.00063, "memory": 4011, "data_time": 0.06333, "loss_cls": 0.23544, "loss_bbox": 0.09699, "loss_kps": 8.93029, "loss": 9.26272, "time": 0.78123}
{"mode": "train", "epoch": 5, "iter": 200, "lr": 0.00063, "memory": 4011, "data_time": 0.05804, "loss_cls": 0.24157, "loss_bbox": 0.09386, "loss_kps": 9.03347, "loss": 9.36889, "time": 0.81612}
{"mode": "train", "epoch": 5, "iter": 250, "lr": 0.00063, "memory": 4011, "data_time": 0.0637, "loss_cls": 0.23268, "loss_bbox": 0.09261, "loss_kps": 7.82752, "loss": 8.15281, "time": 0.80703}
{"mode": "train", "epoch": 5, "iter": 300, "lr": 0.00063, "memory": 4011, "data_time": 0.06206, "loss_cls": 0.23029, "loss_bbox": 0.09138, "loss_kps": 7.70307, "loss": 8.02474, "time": 0.81139}
{"mode": "train", "epoch": 5, "iter": 350, "lr": 0.00063, "memory": 4011, "data_time": 0.06158, "loss_cls": 0.22566, "loss_bbox": 0.0918, "loss_kps": 7.59294, "loss": 7.9104, "time": 0.802}
{"mode": "train", "epoch": 5, "iter": 400, "lr": 0.00063, "memory": 4011, "data_time": 0.06067, "loss_cls": 0.22713, "loss_bbox": 0.08997, "loss_kps": 7.44529, "loss": 7.76239, "time": 0.80691}
{"mode": "train", "epoch": 5, "iter": 450, "lr": 0.00063, "memory": 4011, "data_time": 0.06772, "loss_cls": 0.22963, "loss_bbox": 0.09016, "loss_kps": 8.07263, "loss": 8.39242, "time": 0.58543}
