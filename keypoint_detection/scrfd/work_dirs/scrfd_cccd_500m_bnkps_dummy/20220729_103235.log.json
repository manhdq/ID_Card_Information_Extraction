{"env_info": "sys.platform: linux\nPython: 3.9.11 (main, Mar 29 2022, 19:08:29) [GCC 7.5.0]\nCUDA available: True\nGPU 0: Tesla T4\nCUDA_HOME: /root/miniconda3/envs/manhdq\nNVCC: Cuda compilation tools, release 11.3, V11.3.58\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\nPyTorch: 1.11.0+cu113\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.3\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.2\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.12.0+cu113\nOpenCV: 4.4.0\nMMCV: 1.5.3\nMMCV Compiler: n/a\nMMCV CUDA Compiler: n/a\nMMDetection: 2.7.0+", "config": "optimizer = dict(type='Adam', lr=6.25e-05, weight_decay=0.0005)\noptimizer_config = dict(grad_clip=None)\nlr_mult = 8\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=10,\n    warmup_ratio=0.001,\n    step=[32, 48])\ntotal_epochs = 64\ncheckpoint_config = dict(interval=5)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = '/home/manhdq/ID_Card_Information_Extraction/keypoint_detection/scrfd/work_dirs/scrfd_cccd_500m_bnkps_dummy/best.pth'\nresume_from = None\nworkflow = [('train', 1)]\ndataset_type = 'RetinaFaceDataset'\ndata_root = '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd'\ntrain_root = [\n    '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean_v2'\n]\nval_root = '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean'\nimg_norm_cfg = dict(\n    mean=[127.5, 127.5, 127.5], std=[128.0, 128.0, 128.0], to_rgb=True)\nalbu_train_transforms = [\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(\n                type='Affine',\n                scale=None,\n                rotate=(-90, 90),\n                shear=None,\n                interpolation=0,\n                fit_output=True)\n        ],\n        p=0.6),\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(type='MotionBlur'),\n            dict(type='GaussianBlur', blur_limit=3)\n        ],\n        p=0.2),\n    dict(type='ToGray', p=0.2)\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile', to_float32=True),\n    dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n    dict(\n        type='RandomSquareCrop',\n        crop_choice=[0.3, 0.45, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]),\n    dict(type='Resize', img_scale=(640, 640), keep_ratio=False),\n    dict(\n        type='RandomFlip',\n        flip_ratio=0.5,\n        direction=['horizontal', 'vertical', 'diagonal']),\n    dict(\n        type='PhotoMetricDistortion',\n        brightness_delta=32,\n        contrast_range=(0.5, 1.5),\n        saturation_range=(0.5, 1.5),\n        hue_delta=18),\n    dict(\n        type='Normalize',\n        mean=[127.5, 127.5, 127.5],\n        std=[128.0, 128.0, 128.0],\n        to_rgb=True),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=[\n            'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n            'gt_keypointss'\n        ])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(640, 640),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.0),\n            dict(\n                type='Normalize',\n                mean=[127.5, 127.5, 127.5],\n                std=[128.0, 128.0, 128.0],\n                to_rgb=True),\n            dict(type='Pad', size=(640, 640), pad_val=0),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=32,\n    workers_per_gpu=8,\n    train=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean_v2/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean_v2/images',\n        pipeline=[\n            dict(type='LoadImageFromFile', to_float32=True),\n            dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n            dict(\n                type='RandomSquareCrop',\n                crop_choice=[\n                    0.3, 0.45, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0\n                ]),\n            dict(type='Resize', img_scale=(640, 640), keep_ratio=False),\n            dict(\n                type='RandomFlip',\n                flip_ratio=0.5,\n                direction=['horizontal', 'vertical', 'diagonal']),\n            dict(\n                type='PhotoMetricDistortion',\n                brightness_delta=32,\n                contrast_range=(0.5, 1.5),\n                saturation_range=(0.5, 1.5),\n                hue_delta=18),\n            dict(\n                type='Normalize',\n                mean=[127.5, 127.5, 127.5],\n                std=[128.0, 128.0, 128.0],\n                to_rgb=True),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_keypointss'\n                ])\n        ]),\n    val=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/images',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 640),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', flip_ratio=0.0),\n                    dict(\n                        type='Normalize',\n                        mean=[127.5, 127.5, 127.5],\n                        std=[128.0, 128.0, 128.0],\n                        to_rgb=True),\n                    dict(type='Pad', size=(640, 640), pad_val=0),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    infer=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/images',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 640),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', flip_ratio=0.0),\n                    dict(\n                        type='Normalize',\n                        mean=[127.5, 127.5, 127.5],\n                        std=[128.0, 128.0, 128.0],\n                        to_rgb=True),\n                    dict(type='Pad', size=(640, 640), pad_val=0),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_keypointss'\n                        ])\n                ])\n        ]),\n    test=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/images',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 640),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', flip_ratio=0.0),\n                    dict(\n                        type='Normalize',\n                        mean=[127.5, 127.5, 127.5],\n                        std=[128.0, 128.0, 128.0],\n                        to_rgb=True),\n                    dict(type='Pad', size=(640, 640), pad_val=0),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nmodel = dict(\n    type='SCRFD',\n    backbone=dict(\n        type='MobileNetV1',\n        block_cfg=dict(\n            stage_blocks=(2, 3, 2, 6), stage_planes=[16, 16, 40, 72, 152,\n                                                     288])),\n    neck=dict(\n        type='PAFPN',\n        in_channels=[40, 72, 152, 288],\n        out_channels=16,\n        start_level=1,\n        add_extra_convs='on_output',\n        num_outs=3),\n    bbox_head=dict(\n        type='SCRFDHead',\n        num_classes=1,\n        in_channels=16,\n        stacked_convs=2,\n        feat_channels=64,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        cls_reg_share=True,\n        strides_share=False,\n        dw_conv=True,\n        scale_mode=0,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            ratios=[1.0],\n            scales=[1, 2],\n            base_sizes=[16, 64, 256],\n            strides=[8, 16, 32]),\n        loss_cls=dict(\n            type='QualityFocalLoss',\n            use_sigmoid=True,\n            beta=2.0,\n            loss_weight=1.0),\n        loss_dfl=False,\n        reg_max=8,\n        loss_bbox=dict(type='DIoULoss', loss_weight=1.0),\n        use_kps=True,\n        loss_kps=dict(\n            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.5),\n        train_cfg=dict(\n            assigner=dict(type='ATSSAssigner', topk=9),\n            allowed_border=-1,\n            pos_weight=-1,\n            debug=False),\n        test_cfg=dict(\n            nms_pre=-1,\n            min_bbox_size=0,\n            score_thr=0.02,\n            nms=dict(type='nms', iou_threshold=0.45),\n            max_per_img=-1)))\ntrain_cfg = dict(\n    assigner=dict(type='ATSSAssigner', topk=9),\n    allowed_border=-1,\n    pos_weight=-1,\n    debug=False)\nval_cfg = dict(\n    nms_pre=-1,\n    min_bbox_size=0,\n    score_thr=0.02,\n    nms=dict(type='nms', iou_threshold=0.45),\n    max_per_img=-1)\ntest_cfg = dict(\n    nms_pre=-1,\n    min_bbox_size=0,\n    score_thr=0.02,\n    nms=dict(type='nms', iou_threshold=0.45),\n    max_per_img=-1)\nepoch_multi = 1\nevaluation = dict(interval=5, metric='mAP')\nwork_dir = './work_dirs/scrfd_cccd_500m_bnkps_dummy'\ngpu_ids = range(0, 1)\n", "seed": null, "exp_name": "scrfd_cccd_500m_bnkps_dummy.py"}
{"mode": "val", "epoch": 5, "iter": 11, "lr": 6e-05, "mAP": 0.95674}
{"mode": "val", "epoch": 10, "iter": 11, "lr": 6e-05, "mAP": 0.96528}
{"mode": "val", "epoch": 15, "iter": 11, "lr": 6e-05, "mAP": 0.97217}
{"mode": "val", "epoch": 20, "iter": 11, "lr": 6e-05, "mAP": 0.97839}
{"mode": "val", "epoch": 25, "iter": 11, "lr": 6e-05, "mAP": 0.98548}
{"mode": "val", "epoch": 30, "iter": 11, "lr": 6e-05, "mAP": 0.9858}
{"mode": "val", "epoch": 35, "iter": 11, "lr": 1e-05, "mAP": 0.98674}
{"mode": "val", "epoch": 40, "iter": 11, "lr": 1e-05, "mAP": 0.98566}
{"mode": "val", "epoch": 45, "iter": 11, "lr": 1e-05, "mAP": 0.98709}
{"mode": "val", "epoch": 50, "iter": 11, "lr": 0.0, "mAP": 0.9861}
{"mode": "val", "epoch": 55, "iter": 11, "lr": 0.0, "mAP": 0.98721}
{"mode": "val", "epoch": 60, "iter": 11, "lr": 0.0, "mAP": 0.98747}
