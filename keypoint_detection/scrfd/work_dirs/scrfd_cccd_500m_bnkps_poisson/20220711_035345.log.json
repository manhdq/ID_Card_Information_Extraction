{"env_info": "sys.platform: linux\nPython: 3.9.11 (main, Mar 29 2022, 19:08:29) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1: Tesla T4\nCUDA_HOME: /root/miniconda3/envs/manhdq\nNVCC: Cuda compilation tools, release 11.3, V11.3.58\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\nPyTorch: 1.11.0+cu113\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.3\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.2\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.12.0+cu113\nOpenCV: 4.4.0\nMMCV: 1.5.3\nMMCV Compiler: n/a\nMMCV CUDA Compiler: n/a\nMMDetection: 2.7.0+", "config": "optimizer = dict(type='Adam', lr=0.000625, weight_decay=0.0005)\noptimizer_config = dict(grad_clip=None)\nlr_mult = 8\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=10,\n    warmup_ratio=0.001,\n    step=[32, 48])\ntotal_epochs = 64\ncheckpoint_config = dict(interval=5)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = '/home/manhdq/ID_Card_Information_Extraction/ckpts/keypoint_detector_weights/final_500m_kpts_weights/best.pth'\nresume_from = None\nworkflow = [('train', 1)]\ndataset_type = 'RetinaFaceDataset'\ndata_root = '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd'\ntrain_root = '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/poisson_v1'\nval_root = '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean'\nimg_norm_cfg = dict(\n    mean=[127.5, 127.5, 127.5], std=[128.0, 128.0, 128.0], to_rgb=True)\nalbu_train_transforms = [\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(\n                type='Affine',\n                scale=None,\n                rotate=(-90, 90),\n                shear=None,\n                interpolation=0,\n                fit_output=True)\n        ],\n        p=0.6),\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(type='MotionBlur'),\n            dict(type='GaussianBlur', blur_limit=3)\n        ],\n        p=0.2),\n    dict(type='ToGray', p=0.2)\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile', to_float32=True),\n    dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n    dict(\n        type='RandomSquareCrop',\n        crop_choice=[0.3, 0.45, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]),\n    dict(type='Resize', img_scale=(640, 640), keep_ratio=False),\n    dict(\n        type='RandomFlip',\n        flip_ratio=0.5,\n        direction=['horizontal', 'vertical', 'diagonal']),\n    dict(\n        type='PhotoMetricDistortion',\n        brightness_delta=32,\n        contrast_range=(0.5, 1.5),\n        saturation_range=(0.5, 1.5),\n        hue_delta=18),\n    dict(\n        type='Normalize',\n        mean=[127.5, 127.5, 127.5],\n        std=[128.0, 128.0, 128.0],\n        to_rgb=True),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=[\n            'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n            'gt_keypointss'\n        ])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(640, 640),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.0),\n            dict(\n                type='Normalize',\n                mean=[127.5, 127.5, 127.5],\n                std=[128.0, 128.0, 128.0],\n                to_rgb=True),\n            dict(type='Pad', size=(640, 640), pad_val=0),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=64,\n    workers_per_gpu=8,\n    train=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/poisson_v1/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/poisson_v1/images',\n        pipeline=[\n            dict(type='LoadImageFromFile', to_float32=True),\n            dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n            dict(\n                type='RandomSquareCrop',\n                crop_choice=[\n                    0.3, 0.45, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0\n                ]),\n            dict(type='Resize', img_scale=(640, 640), keep_ratio=False),\n            dict(\n                type='RandomFlip',\n                flip_ratio=0.5,\n                direction=['horizontal', 'vertical', 'diagonal']),\n            dict(\n                type='PhotoMetricDistortion',\n                brightness_delta=32,\n                contrast_range=(0.5, 1.5),\n                saturation_range=(0.5, 1.5),\n                hue_delta=18),\n            dict(\n                type='Normalize',\n                mean=[127.5, 127.5, 127.5],\n                std=[128.0, 128.0, 128.0],\n                to_rgb=True),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_keypointss'\n                ])\n        ]),\n    val=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/images',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_keypoints=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 640),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', flip_ratio=0.0),\n                    dict(\n                        type='Normalize',\n                        mean=[127.5, 127.5, 127.5],\n                        std=[128.0, 128.0, 128.0],\n                        to_rgb=True),\n                    dict(type='Pad', size=(640, 640), pad_val=0),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_keypointss'\n                        ])\n                ])\n        ]),\n    test=dict(\n        type='RetinaFaceDataset',\n        ann_file=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/annotations.txt',\n        img_prefix=\n        '/home/manhdq/ID_Card_Information_Extraction/datasets/cccd/valid_cccd_clean/images',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 640),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip', flip_ratio=0.0),\n                    dict(\n                        type='Normalize',\n                        mean=[127.5, 127.5, 127.5],\n                        std=[128.0, 128.0, 128.0],\n                        to_rgb=True),\n                    dict(type='Pad', size=(640, 640), pad_val=0),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nmodel = dict(\n    type='SCRFD',\n    backbone=dict(\n        type='MobileNetV1',\n        block_cfg=dict(\n            stage_blocks=(2, 3, 2, 6), stage_planes=[16, 16, 40, 72, 152,\n                                                     288])),\n    neck=dict(\n        type='PAFPN',\n        in_channels=[40, 72, 152, 288],\n        out_channels=16,\n        start_level=1,\n        add_extra_convs='on_output',\n        num_outs=3),\n    bbox_head=dict(\n        type='SCRFDHead',\n        num_classes=1,\n        in_channels=16,\n        stacked_convs=2,\n        feat_channels=64,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        cls_reg_share=True,\n        strides_share=False,\n        dw_conv=True,\n        scale_mode=0,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            ratios=[1.0],\n            scales=[1, 2],\n            base_sizes=[16, 64, 256],\n            strides=[8, 16, 32]),\n        loss_cls=dict(\n            type='QualityFocalLoss',\n            use_sigmoid=True,\n            beta=2.0,\n            loss_weight=1.0),\n        loss_dfl=False,\n        reg_max=8,\n        loss_bbox=dict(type='DIoULoss', loss_weight=1.0),\n        use_kps=True,\n        loss_kps=dict(\n            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.5),\n        train_cfg=dict(\n            assigner=dict(type='ATSSAssigner', topk=9),\n            allowed_border=-1,\n            pos_weight=-1,\n            debug=False),\n        test_cfg=dict(\n            nms_pre=-1,\n            min_bbox_size=0,\n            score_thr=0.02,\n            nms=dict(type='nms', iou_threshold=0.45),\n            max_per_img=-1)))\ntrain_cfg = dict(\n    assigner=dict(type='ATSSAssigner', topk=9),\n    allowed_border=-1,\n    pos_weight=-1,\n    debug=False)\nval_cfg = dict(\n    nms_pre=-1,\n    min_bbox_size=0,\n    score_thr=0.02,\n    nms=dict(type='nms', iou_threshold=0.45),\n    max_per_img=-1)\ntest_cfg = dict(\n    nms_pre=-1,\n    min_bbox_size=0,\n    score_thr=0.02,\n    nms=dict(type='nms', iou_threshold=0.45),\n    max_per_img=-1)\nepoch_multi = 1\nevaluation = dict(interval=5, metric='mAP')\nwork_dir = './work_dirs/scrfd_cccd_500m_bnkps_poisson'\ngpu_ids = range(0, 1)\n", "seed": 42, "exp_name": "scrfd_cccd_500m_bnkps_poisson.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.00063, "memory": 7994, "data_time": 0.25927, "loss_cls": 0.27274, "loss_bbox": 0.09796, "loss_kps": 32.68574, "loss": 33.05643, "time": 1.14487}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.00063, "memory": 7994, "data_time": 0.12407, "loss_cls": 0.25894, "loss_bbox": 0.10632, "loss_kps": 26.01413, "loss": 26.37938, "time": 0.99013}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.00063, "memory": 7994, "data_time": 0.12907, "loss_cls": 0.24828, "loss_bbox": 0.10328, "loss_kps": 21.85498, "loss": 22.20654, "time": 0.99958}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.00063, "memory": 7994, "data_time": 0.12646, "loss_cls": 0.25284, "loss_bbox": 0.10433, "loss_kps": 20.80173, "loss": 21.15891, "time": 0.99831}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.00063, "memory": 7994, "data_time": 0.26608, "loss_cls": 0.2423, "loss_bbox": 0.0995, "loss_kps": 15.95998, "loss": 16.30177, "time": 1.17404}
{"mode": "train", "epoch": 2, "iter": 100, "lr": 0.00063, "memory": 7994, "data_time": 0.12506, "loss_cls": 0.2381, "loss_bbox": 0.09764, "loss_kps": 14.75467, "loss": 15.09041, "time": 1.00239}
{"mode": "train", "epoch": 2, "iter": 150, "lr": 0.00063, "memory": 7994, "data_time": 0.12724, "loss_cls": 0.23234, "loss_bbox": 0.09624, "loss_kps": 13.81494, "loss": 14.14351, "time": 1.00001}
{"mode": "train", "epoch": 2, "iter": 200, "lr": 0.00063, "memory": 7994, "data_time": 0.12772, "loss_cls": 0.24344, "loss_bbox": 0.09278, "loss_kps": 13.4804, "loss": 13.81663, "time": 1.00279}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.00063, "memory": 7994, "data_time": 0.28678, "loss_cls": 0.22467, "loss_bbox": 0.08958, "loss_kps": 12.37087, "loss": 12.68512, "time": 1.20332}
{"mode": "train", "epoch": 3, "iter": 100, "lr": 0.00063, "memory": 7994, "data_time": 0.12618, "loss_cls": 0.21946, "loss_bbox": 0.08924, "loss_kps": 12.36807, "loss": 12.67677, "time": 0.99954}
{"mode": "train", "epoch": 3, "iter": 150, "lr": 0.00063, "memory": 7994, "data_time": 0.13222, "loss_cls": 0.22368, "loss_bbox": 0.08901, "loss_kps": 11.67699, "loss": 11.98968, "time": 1.01775}
{"mode": "train", "epoch": 3, "iter": 200, "lr": 0.00063, "memory": 7994, "data_time": 0.13293, "loss_cls": 0.22162, "loss_bbox": 0.08629, "loss_kps": 11.7109, "loss": 12.01881, "time": 1.00771}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 0.00063, "memory": 7994, "data_time": 0.28, "loss_cls": 0.21663, "loss_bbox": 0.08451, "loss_kps": 10.62917, "loss": 10.93031, "time": 1.18638}
{"mode": "train", "epoch": 4, "iter": 100, "lr": 0.00063, "memory": 7994, "data_time": 0.12701, "loss_cls": 0.2207, "loss_bbox": 0.08532, "loss_kps": 11.0531, "loss": 11.35912, "time": 1.01002}
{"mode": "train", "epoch": 4, "iter": 150, "lr": 0.00063, "memory": 7994, "data_time": 0.13124, "loss_cls": 0.21359, "loss_bbox": 0.08258, "loss_kps": 10.86804, "loss": 11.16421, "time": 1.01324}
{"mode": "train", "epoch": 4, "iter": 200, "lr": 0.00063, "memory": 7994, "data_time": 0.13293, "loss_cls": 0.21929, "loss_bbox": 0.08349, "loss_kps": 10.2407, "loss": 10.54348, "time": 1.01061}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 0.00063, "memory": 7994, "data_time": 0.27466, "loss_cls": 0.21067, "loss_bbox": 0.08152, "loss_kps": 10.98697, "loss": 11.27916, "time": 1.2236}
{"mode": "train", "epoch": 5, "iter": 100, "lr": 0.00063, "memory": 7994, "data_time": 0.1292, "loss_cls": 0.20899, "loss_bbox": 0.08082, "loss_kps": 9.72153, "loss": 10.01133, "time": 1.00198}
{"mode": "train", "epoch": 5, "iter": 150, "lr": 0.00063, "memory": 7994, "data_time": 0.13639, "loss_cls": 0.21041, "loss_bbox": 0.08291, "loss_kps": 10.23818, "loss": 10.5315, "time": 1.01748}
{"mode": "train", "epoch": 5, "iter": 200, "lr": 0.00063, "memory": 7994, "data_time": 0.1265, "loss_cls": 0.21178, "loss_bbox": 0.08048, "loss_kps": 9.71358, "loss": 10.00584, "time": 1.01213}
